================================================================================
MLOPS BEST PRACTICES AND PATTERNS - UNIVERSAL GUIDE
================================================================================

This document provides universal MLOps best practices, patterns, and guidelines
applicable to any machine learning project, regardless of tech stack or domain.
Based on real-world experience and industry standards.

================================================================================
TABLE OF CONTENTS
================================================================================

1. MLOps Pipeline Architecture Patterns
2. Experiment Tracking and Model Registry
3. Feature Engineering Best Practices
4. Model Training and Evaluation
5. Model Deployment Strategies
6. CI/CD for ML Projects
7. Common Pitfalls and How to Avoid Them
8. Debugging and Troubleshooting
9. Production Readiness Checklist
10. GitHub Actions Secrets and Environment Variables Management

================================================================================
1. MLOPS PIPELINE ARCHITECTURE PATTERNS
================================================================================

CORE PRINCIPLE: Separation of Concerns
--------------------------------------
Always separate your ML pipeline into distinct, modular stages:

Stage 1: Data Processing
- Input: Raw data from various sources
- Output: Cleaned, validated data
- Responsibilities:
  * Data validation and quality checks
  * Missing value handling
  * Outlier detection and removal
  * Data type conversions
  * Duplicate removal

Stage 2: Feature Engineering
- Input: Cleaned data
- Output: Transformed features + fitted preprocessor/transformer
- Responsibilities:
  * Feature creation and derivation
  * Feature scaling/normalization
  * Categorical encoding
  * Feature selection
  * **CRITICAL**: Save fitted transformers for inference

Stage 3: Model Training
- Input: Featured data + model configuration
- Output: Trained model + evaluation metrics
- Responsibilities:
  * Model selection and hyperparameter tuning
  * Train-test splitting
  * Model fitting
  * Evaluation and metrics logging
  * Model serialization

Stage 4: Model Evaluation
- Input: Trained model + validation/test data
- Output: Performance metrics + visualizations
- Responsibilities:
  * Cross-validation
  * Performance metrics calculation
  * Error analysis
  * Model comparison

Stage 5: Model Deployment
- Input: Production-ready model
- Output: Inference service/API
- Responsibilities:
  * Model loading and initialization
  * Request validation
  * Feature transformation (using saved transformers)
  * Prediction generation
  * Response formatting


WHY THIS SEPARATION MATTERS:
---------------------------
‚úì Each stage can be tested independently
‚úì Easy to debug specific components
‚úì Enables parallel development
‚úì Simplifies CI/CD pipeline creation
‚úì Makes it easy to retrain specific stages
‚úì Improves code reusability


ANTI-PATTERN: All-in-one scripts
--------------------------------
‚ùå DON'T: Create single scripts that do data processing, feature engineering,
         and model training all at once
‚úì DO: Create modular scripts with clear inputs and outputs


PATTERN: Command-Line Interface for Each Stage
---------------------------------------------
Each pipeline stage should accept command-line arguments:

‚úì DO:
python src/data/process.py --input raw.csv --output cleaned.csv
python src/features/engineer.py --input cleaned.csv --output features.csv --transformer transformer.pkl
python src/models/train.py --config config.yaml --data features.csv --output model.pkl

‚ùå DON'T: Hard-code file paths inside scripts


PATTERN: Configuration Over Code
--------------------------------
Use configuration files (YAML/JSON) for:
- Model hyperparameters
- Feature engineering parameters
- Data processing rules
- Pipeline settings

‚úì DO:
# config.yaml
model:
  type: "RandomForest"
  params:
    n_estimators: 100
    max_depth: 10

‚ùå DON'T: Hard-code hyperparameters in training scripts

================================================================================
2. EXPERIMENT TRACKING AND MODEL REGISTRY
================================================================================

CRITICAL RULE: Always Track Experiments
---------------------------------------
Never train models without experiment tracking.

WHAT TO LOG:
-----------
1. Hyperparameters (ALL of them, including defaults)
2. Metrics (training, validation, test)
3. Model artifacts
4. Dataset versions/checksums
5. Feature names and transformations
6. System information:
   - Python version
   - Library versions (scikit-learn, tensorflow, etc.)
   - Hardware specs (CPU/GPU)
   - Training duration
7. Git commit hash
8. Random seeds
9. Data splits (train/val/test sizes)


MLFLOW BEST PRACTICES:
---------------------

1. Experiment Naming Convention:
   ‚úì DO: Use descriptive names like "house_price_xgboost_v2"
   ‚ùå DON'T: Use generic names like "experiment_1"

2. Run Naming:
   ‚úì DO: Include key info like "lr_0.01_batch_128_epoch_50"
   ‚ùå DON'T: Use default auto-generated names

3. Experiment Organization:
   - One experiment per model type or use case
   - Use tags to categorize runs
   - Add descriptions to experiments

4. Model Registry Usage:
   - Register only production-worthy models
   - Use stages: None ‚Üí Staging ‚Üí Production ‚Üí Archived
   - Add version descriptions explaining changes
   - Tag models with metadata

5. Artifact Storage:
   - Log preprocessors/transformers alongside models
   - Save feature engineering code snapshots
   - Include model evaluation plots
   - Store example predictions


EXPERIMENT CREATION PATTERN:
---------------------------

‚úì DO: Create or get experiment explicitly

import mlflow

# This creates experiment if it doesn't exist
experiment = mlflow.set_experiment("my_experiment")
print(f"Experiment ID: {experiment.experiment_id}")

with mlflow.start_run(run_name="descriptive_run_name"):
    # Log everything
    mlflow.log_params(hyperparameters)
    mlflow.log_metrics(metrics)
    mlflow.log_artifact("model.pkl")


‚ùå DON'T: Assume experiment exists or use default experiment

with mlflow.start_run():  # Uses default experiment (bad practice)
    pass


CRITICAL BUG TO AVOID:
---------------------
ISSUE: "Could not find experiment with ID 0"

ROOT CAUSE:
- Trying to use an experiment that doesn't exist
- Not creating experiment before starting run
- Conditional experiment creation (only when tracking URI is set)

SOLUTION:
# ALWAYS call set_experiment unconditionally
if tracking_uri:
    mlflow.set_tracking_uri(tracking_uri)

# This line should ALWAYS execute (not inside if block)
experiment = mlflow.set_experiment(experiment_name)


TRACKING BACKEND CHOICES:
------------------------
Development:
- File-based: mlruns/ directory (simple, local)
- Warning: "Filesystem tracking backend deprecated" is expected

Production:
- Database backend: PostgreSQL, MySQL
- Format: "postgresql://user:pass@host:port/db"
- Or cloud: Databricks, AWS SageMaker, Azure ML

================================================================================
3. FEATURE ENGINEERING BEST PRACTICES
================================================================================

GOLDEN RULE: Training-Inference Consistency
-------------------------------------------
Feature engineering MUST be identical in training and inference.

THE PREPROCESSOR PATTERN:
-------------------------

‚úì CORRECT APPROACH:

# Training Phase (feature engineering script)
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
import pickle

# Create transformations
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(), categorical_features)
])

# Fit on training data
preprocessor.fit(X_train)

# Save the FITTED preprocessor
with open('preprocessor.pkl', 'wb') as f:
    pickle.dump(preprocessor, f)

# Transform data
X_transformed = preprocessor.transform(X)


# Inference Phase (API/serving)
import pickle

# Load the SAME preprocessor
with open('preprocessor.pkl', 'rb') as f:
    preprocessor = pickle.load(f)

# Apply SAME transformations
X_new_transformed = preprocessor.transform(X_new)


‚ùå WRONG APPROACH: Re-creating transformations

# Training
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Inference (WRONG - creates NEW scaler)
scaler = StandardScaler()  # This is a DIFFERENT scaler!
X_new_scaled = scaler.fit_transform(X_new)  # WRONG - fitting on new data!


FEATURE ENGINEERING CHECKLIST:
------------------------------
‚ñ° All transformations are in a single pipeline/preprocessor
‚ñ° Preprocessor is fitted ONLY on training data
‚ñ° Fitted preprocessor is saved as artifact
‚ñ° Same preprocessor is loaded during inference
‚ñ° Feature names are consistent across train/inference
‚ñ° Feature order is preserved
‚ñ° All feature engineering logic is version controlled


WHEN TO RETRAIN PREPROCESSOR:
-----------------------------
You MUST retrain the preprocessor when:
‚úì Adding new features
‚úì Removing features
‚úì Changing transformation logic
‚úì Updating encoding schemes
‚úì Modifying scaling parameters
‚úì Changing categorical categories

Process:
1. Modify feature engineering code
2. Re-run feature engineering script (creates new preprocessor)
3. Re-run model training (with new preprocessor)
4. Deploy both new model AND new preprocessor together


FEATURE ENGINEERING ANTI-PATTERNS:
----------------------------------

‚ùå Anti-Pattern 1: Feature leakage
Example: Using test set statistics in transformations
DON'T: scaler.fit(pd.concat([X_train, X_test]))
DO: scaler.fit(X_train)

‚ùå Anti-Pattern 2: Inconsistent feature engineering
Example: Different logic in training vs inference
DON'T: Have separate feature engineering code for train/serve
DO: Use the same preprocessor artifact

‚ùå Anti-Pattern 3: Hard-coded feature values
Example: Manual scaling with hard-coded mean/std
DON'T: X_scaled = (X - 50) / 10  # Where do 50 and 10 come from?
DO: Use fitted scaler from training

‚ùå Anti-Pattern 4: Missing features in inference
Example: Features used in training not available in inference
DO: Document required features in schema
DO: Validate input features before prediction

================================================================================
4. MODEL TRAINING AND EVALUATION
================================================================================

PRE-TRAINING CHECKLIST:
----------------------
‚ñ° Data is properly split (train/validation/test)
‚ñ° No data leakage between splits
‚ñ° Features are properly engineered
‚ñ° Baseline model established
‚ñ° Evaluation metrics defined
‚ñ° Random seeds set for reproducibility


TRAIN-TEST SPLIT BEST PRACTICES:
--------------------------------

‚úì DO: Use stratified splitting for classification
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,  # Always set for reproducibility
    stratify=y  # For classification
)

‚úì DO: Use time-based splitting for time series
# For time series: chronological split
split_date = '2023-01-01'
train = df[df['date'] < split_date]
test = df[df['date'] >= split_date]

‚ùå DON'T: Shuffle time series data
‚ùå DON'T: Use random splits for time-dependent data


HYPERPARAMETER TUNING:
---------------------

Pattern 1: Grid Search
- Exhaustive search over parameter grid
- Use for small parameter spaces
- Example: 2-3 parameters with few values each

Pattern 2: Random Search
- Random sampling from parameter distributions
- More efficient than grid search
- Use for larger parameter spaces

Pattern 3: Bayesian Optimization
- Smart search using previous results
- Most efficient for expensive models
- Tools: Optuna, Hyperopt

‚úì DO: Always use cross-validation during tuning
‚úì DO: Log ALL hyperparameter combinations tried
‚ùå DON'T: Tune on test set (use validation set)


MODEL EVALUATION METRICS:
------------------------

Regression:
- MAE (Mean Absolute Error): Easy to interpret
- RMSE (Root Mean Squared Error): Penalizes large errors
- R¬≤ (R-squared): Explains variance (0-1, higher is better)
- MAPE (Mean Absolute Percentage Error): For relative errors

Classification:
- Accuracy: Overall correctness (use when classes balanced)
- Precision: How many predicted positives are correct
- Recall: How many actual positives were found
- F1-Score: Harmonic mean of precision and recall
- ROC-AUC: Overall discrimination ability
- Confusion Matrix: Detailed error analysis

‚úì DO: Use multiple metrics
‚úì DO: Choose metrics that align with business goals
‚ùå DON'T: Rely on accuracy alone for imbalanced data


REPRODUCIBILITY REQUIREMENTS:
-----------------------------
1. Set random seeds everywhere:
   - Python: random.seed(42)
   - NumPy: np.random.seed(42)
   - Model-specific seeds

2. Document dependencies:
   - Create requirements.txt or environment.yml
   - Pin versions: scikit-learn==1.3.0 (not >=1.3.0)

3. Version control:
   - Git commit all code
   - Tag model versions with git tags
   - Include git hash in MLflow tags

4. Data versioning:
   - Use DVC (Data Version Control)
   - Or save data checksums
   - Document data sources and collection dates

================================================================================
5. MODEL DEPLOYMENT STRATEGIES
================================================================================

DEPLOYMENT PATTERNS:
-------------------

Pattern 1: REST API (Most Common)
Technology: FastAPI, Flask, Django REST
Use Case: Real-time predictions, low-to-medium volume
Pros: Easy to implement, language-agnostic clients
Cons: Synchronous, may not scale to very high volume

Pattern 2: Batch Prediction
Technology: Airflow, Prefect, scheduled scripts
Use Case: Periodic predictions, large datasets
Pros: Efficient for large volumes, can optimize resources
Cons: Not real-time, results delayed

Pattern 3: Streaming
Technology: Kafka, Kinesis, Spark Streaming
Use Case: Real-time, high-volume predictions
Pros: Handles high throughput, low latency
Cons: Complex infrastructure

Pattern 4: Embedded
Technology: TensorFlow Lite, ONNX
Use Case: Mobile/edge devices
Pros: No network required, fast inference
Cons: Limited model complexity, deployment challenges


API DESIGN BEST PRACTICES:
--------------------------

‚úì DO: Use Pydantic for request/response validation

from pydantic import BaseModel, Field

class PredictionRequest(BaseModel):
    feature1: float = Field(..., ge=0, description="Must be positive")
    feature2: str = Field(..., regex="^(cat1|cat2|cat3)$")

class PredictionResponse(BaseModel):
    prediction: float
    confidence: float
    model_version: str


‚úì DO: Include health check endpoint

@app.get("/health")
def health_check():
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "version": "1.0.0"
    }


‚úì DO: Add versioning to API

@app.post("/v1/predict")  # Version in URL
def predict_v1(request: PredictionRequest):
    pass


‚úì DO: Return prediction confidence/uncertainty

return {
    "prediction": prediction,
    "confidence_interval": [lower_bound, upper_bound],
    "probability": probability
}


‚úì DO: Handle errors gracefully

from fastapi import HTTPException

try:
    prediction = model.predict(features)
except ValueError as e:
    raise HTTPException(status_code=400, detail=str(e))
except Exception as e:
    raise HTTPException(status_code=500, detail="Internal server error")


MODEL LOADING STRATEGIES:
-------------------------

Strategy 1: Load on Startup (Recommended for small models)
- Load model when application starts
- Fast inference, but increases startup time
- Suitable for models < 1GB

Strategy 2: Lazy Loading
- Load model on first prediction request
- Fast startup, but first request is slow
- Use caching to keep model in memory

Strategy 3: Model Server
- Dedicated model serving infrastructure
- Examples: TensorFlow Serving, TorchServe, MLflow Models
- Use for production-grade deployments


CRITICAL: Feature Transformation in Inference
---------------------------------------------

‚úì CORRECT Pattern:

# Load BOTH model and preprocessor
model = joblib.load('model.pkl')
preprocessor = joblib.load('preprocessor.pkl')

def predict(input_data):
    # 1. Recreate any derived features
    input_data['feature_derived'] = input_data['a'] / input_data['b']

    # 2. Apply SAVED preprocessor
    features_transformed = preprocessor.transform(input_data)

    # 3. Predict
    prediction = model.predict(features_transformed)
    return prediction


‚ùå WRONG: Creating new transformations

def predict(input_data):
    # WRONG - creating new scaler instead of using saved one
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(input_data)
    prediction = model.predict(features_scaled)
    return prediction

================================================================================
6. CI/CD FOR ML PROJECTS
================================================================================

ML PIPELINE AUTOMATION STAGES:
------------------------------

Stage 1: Code Quality Checks
- Linting (flake8, pylint, black)
- Type checking (mypy)
- Security scanning (bandit)

Stage 2: Unit Testing
- Test data processing functions
- Test feature engineering logic
- Test model training functions
- Test API endpoints

Stage 3: Data Validation
- Check data schema
- Validate data quality
- Check for data drift

Stage 4: ML Pipeline Execution
- Run data processing
- Run feature engineering
- Run model training (optional - can be manual)

Stage 5: Model Validation
- Evaluate model performance
- Check metrics against thresholds
- Compare with baseline model

Stage 6: Deployment
- Build Docker images
- Deploy to staging
- Run integration tests
- Deploy to production (manual approval)


GITHUB ACTIONS PATTERN FOR ML:
------------------------------

Triggers:
‚úì DO: Trigger on code changes (src/, configs/)
‚úì DO: Trigger on data changes (data/raw/)
‚ùå DON'T: Trigger on every commit to any file

Artifact Management:
‚úì DO: Save pipeline outputs as artifacts
‚úì DO: Use appropriate retention periods (7-30 days)
‚úì DO: Tag artifacts with version/commit hash

Job Dependencies:
‚úì DO: Use needs: to create pipeline dependencies
‚úì DO: Fail fast if upstream jobs fail

Example structure:
```yaml
jobs:
  data-processing:
    runs-on: ubuntu-latest
    steps:
      - name: Process data
      - name: Upload artifact

  feature-engineering:
    needs: data-processing
    runs-on: ubuntu-latest
    steps:
      - name: Download data artifact
      - name: Engineer features
      - name: Upload artifacts

  model-training:
    needs: feature-engineering
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
      - name: Train model
      - name: Upload model
```


MANUAL GATES FOR MODEL DEPLOYMENT:
----------------------------------
‚úì DO: Require manual approval for production deployment
‚úì DO: Automate deployment to staging
‚úì DO: Run automated tests in staging before production
‚ùå DON'T: Auto-deploy models to production without review


MODEL DEPLOYMENT CHECKLIST:
---------------------------
‚ñ° Model performance meets thresholds
‚ñ° No data leakage detected
‚ñ° Inference latency acceptable
‚ñ° API tests pass
‚ñ° Load testing completed
‚ñ° Rollback plan in place
‚ñ° Monitoring configured
‚ñ° Alerts set up

================================================================================
7. COMMON PITFALLS AND HOW TO AVOID THEM
================================================================================

PITFALL 1: Data Leakage
-----------------------
PROBLEM: Information from test set leaks into training

Common Causes:
‚ùå Fitting transformers on entire dataset
‚ùå Using global statistics (mean, std) from all data
‚ùå Feature engineering using future information

Prevention:
‚úì Always fit on training data only
‚úì Use pipelines to prevent leakage
‚úì Be careful with time series features


PITFALL 2: Train-Serve Skew
---------------------------
PROBLEM: Different behavior in training vs production

Common Causes:
‚ùå Different feature engineering logic
‚ùå Different library versions
‚ùå Different data preprocessing
‚ùå Missing features in production

Prevention:
‚úì Use same preprocessor in train and serve
‚úì Pin all dependency versions
‚úì Validate input schema
‚úì Test inference pipeline with training data


PITFALL 3: Missing Experiment Tracking
--------------------------------------
PROBLEM: Can't reproduce results or compare models

Common Causes:
‚ùå Not logging hyperparameters
‚ùå Not saving random seeds
‚ùå Not tracking code versions

Prevention:
‚úì Always use experiment tracking (MLflow)
‚úì Log everything: params, metrics, artifacts
‚úì Include git commit hash


PITFALL 4: Hardcoded Values
---------------------------
PROBLEM: Can't easily change configurations

Common Causes:
‚ùå File paths in code
‚ùå Hyperparameters in code
‚ùå Feature names in code

Prevention:
‚úì Use configuration files
‚úì Use command-line arguments
‚úì Use environment variables


PITFALL 5: Not Handling Missing Models
--------------------------------------
PROBLEM: Experiment creation fails if model doesn't exist

Example Issue:
```python
# This fails if experiment doesn't exist
mlflow.set_tracking_uri(uri)
if uri:
    mlflow.set_experiment(name)  # Only sets if uri exists!

# Later...
mlflow.start_run()  # ERROR: No experiment set!
```

Solution:
```python
# Set tracking URI (optional)
if uri:
    mlflow.set_tracking_uri(uri)

# ALWAYS set experiment (creates if doesn't exist)
experiment = mlflow.set_experiment(name)
```


PITFALL 6: Version Mismatches
-----------------------------
PROBLEM: Model fails to load due to library version differences

Common Causes:
‚ùå Using unpinned dependencies (>=)
‚ùå Different Python versions
‚ùå Different OS/architecture

Prevention:
‚úì Pin all versions: scikit-learn==1.3.0
‚úì Use Docker for consistent environments
‚úì Log Python and library versions with model
‚úì Test model loading in clean environment


PITFALL 7: No Error Handling
----------------------------
PROBLEM: Pipeline fails without clear error messages

Prevention:
‚úì Add try-except blocks with meaningful messages
‚úì Log errors with context
‚úì Validate inputs early
‚úì Return informative error responses from APIs

================================================================================
8. DEBUGGING AND TROUBLESHOOTING
================================================================================

SYSTEMATIC DEBUGGING APPROACH:
------------------------------

Step 1: Isolate the Problem
- Which pipeline stage is failing?
- Is it data, features, model, or deployment?

Step 2: Check Inputs
- Verify input files exist
- Check file sizes and row counts
- Validate data schema

Step 3: Check Outputs
- Verify output files are created
- Check file sizes make sense
- Inspect first few rows

Step 4: Check Logs
- Read error messages carefully
- Look for stack traces
- Check MLflow logs

Step 5: Test in Isolation
- Run failing component separately
- Use minimal test data
- Add verbose logging


COMMON ERROR PATTERNS:
---------------------

Error: "Module not found"
Solution:
- Activate virtual environment
- Install dependencies: pip install -r requirements.txt
- Check Python path: which python

Error: "File not found"
Solution:
- Check file exists: ls -lh <file>
- Verify absolute vs relative paths
- Check file permissions

Error: "Could not find experiment with ID X"
Solution:
- Set experiment explicitly: mlflow.set_experiment()
- Check MLflow tracking URI is correct
- Verify MLflow server is running

Error: "Feature names don't match"
Solution:
- Ensure same features in train and inference
- Check feature order
- Verify preprocessor was saved correctly

Error: "Shape mismatch"
Solution:
- Check input dimensions
- Verify preprocessing is consistent
- Inspect feature counts


DEBUGGING TOOLS:
---------------

1. Logging:
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

logger.info(f"Processing {len(df)} rows")
logger.debug(f"Features: {df.columns.tolist()}")
```

2. Assertions:
```python
assert df.shape[0] > 0, "Empty dataframe!"
assert 'price' in df.columns, "Missing target column"
```

3. Verification Scripts:
```python
# verify_pipeline.py
def verify_data_processing():
    assert os.path.exists('cleaned_data.csv')
    df = pd.read_csv('cleaned_data.csv')
    assert df.isnull().sum().sum() == 0
    print("‚úì Data processing OK")

def verify_feature_engineering():
    assert os.path.exists('features.csv')
    assert os.path.exists('preprocessor.pkl')
    print("‚úì Feature engineering OK")
```

================================================================================
9. PRODUCTION READINESS CHECKLIST
================================================================================

CODE QUALITY:
------------
‚ñ° All code is version controlled (Git)
‚ñ° Code follows style guide (PEP 8 for Python)
‚ñ° Code is well-documented
‚ñ° Unit tests written and passing
‚ñ° Integration tests written and passing
‚ñ° No hardcoded secrets or credentials

DATA:
----
‚ñ° Data validation checks in place
‚ñ° Data quality monitoring configured
‚ñ° Data versioning implemented
‚ñ° Backup strategy defined

MODEL:
-----
‚ñ° Model performance meets requirements
‚ñ° Model is registered in model registry
‚ñ° Model artifacts are versioned
‚ñ° Model can be loaded and used for inference
‚ñ° Preprocessing pipeline is saved and tested

EXPERIMENT TRACKING:
-------------------
‚ñ° All experiments logged to MLflow/Weights & Biases
‚ñ° Hyperparameters documented
‚ñ° Metrics tracked
‚ñ° Model artifacts saved
‚ñ° System information logged

DEPLOYMENT:
----------
‚ñ° API endpoints tested
‚ñ° Health check endpoint implemented
‚ñ° Error handling in place
‚ñ° Input validation implemented
‚ñ° Response time acceptable (<100ms for most use cases)
‚ñ° Load testing completed
‚ñ° Docker images built and tested

MONITORING:
----------
‚ñ° Application logs configured
‚ñ° Model performance monitoring set up
‚ñ° Data drift detection implemented
‚ñ° Alerts configured for failures
‚ñ° Metrics dashboards created

DOCUMENTATION:
-------------
‚ñ° README with setup instructions
‚ñ° API documentation generated
‚ñ° Model documentation written
‚ñ° Deployment guide created
‚ñ° Troubleshooting guide available

OPERATIONS:
----------
‚ñ° Rollback procedure documented
‚ñ° Incident response plan in place
‚ñ° On-call rotation defined
‚ñ° Runbook created

COMPLIANCE & SECURITY:
---------------------
‚ñ° Model bias evaluated
‚ñ° Privacy requirements met
‚ñ° Security scan completed
‚ñ° Access controls implemented
‚ñ° Audit logging enabled

================================================================================
KEY TAKEAWAYS
================================================================================

1. MODULARITY: Keep pipeline stages separate and testable

2. CONSISTENCY: Use same preprocessing in training and inference

3. TRACKING: Log everything - you never know what you'll need later

4. VERSIONING: Version code, data, models, and dependencies

5. TESTING: Test each component independently before integration

6. CONFIGURATION: Use config files, not hardcoded values

7. ERROR HANDLING: Fail gracefully with informative messages

8. DOCUMENTATION: Document assumptions, decisions, and procedures

9. MONITORING: Watch for data drift and performance degradation

10. AUTOMATION: Automate repetitive tasks, but keep humans in the loop
    for critical decisions

================================================================================
RESOURCES AND FURTHER READING
================================================================================

Books:
- "Designing Machine Learning Systems" by Chip Huyen
- "Machine Learning Engineering" by Andriy Burkov
- "Building Machine Learning Powered Applications" by Emmanuel Ameisen

Tools:
- Experiment Tracking: MLflow, Weights & Biases, Neptune.ai
- Feature Stores: Feast, Tecton
- Model Serving: BentoML, Seldon Core, KServe
- Orchestration: Airflow, Prefect, Kubeflow
- Monitoring: Evidently AI, WhyLabs, Arize

================================================================================
10. GITHUB ACTIONS SECRETS AND ENVIRONMENT VARIABLES MANAGEMENT
================================================================================

CRITICAL ISSUE: Missing Secrets in CI/CD Pipeline
-------------------------------------------------
PROBLEM: "Error: Password required" when trying to push Docker images to registry

This is one of the most common issues when setting up CI/CD pipelines for ML
projects that involve Docker image deployment.

ROOT CAUSE:
-----------
‚ùå GitHub Actions workflow requires authentication credentials (secrets)
‚ùå DockerHub (or other container registry) credentials not configured in GitHub
‚ùå Secrets are not automatically available - must be explicitly set up
‚ùå Confusion between repository variables and secrets

UNDERSTANDING GITHUB SECRETS VS VARIABLES:
-----------------------------------------

Secrets (Encrypted, Sensitive):
- Used for passwords, tokens, API keys
- Never exposed in logs
- Encrypted at rest
- Examples: DOCKERHUB_TOKEN, AWS_SECRET_ACCESS_KEY, DATABASE_PASSWORD
- Access: ${{ secrets.SECRET_NAME }}

Variables (Plain Text, Non-Sensitive):
- Used for configuration values
- Visible in logs
- Not encrypted
- Examples: DOCKERHUB_USERNAME, ENVIRONMENT_NAME, API_URL
- Access: ${{ vars.VARIABLE_NAME }}

‚úì DO: Use secrets for ALL sensitive data
‚úì DO: Use variables for non-sensitive configuration
‚ùå DON'T: Put passwords in variables
‚ùå DON'T: Hardcode credentials in workflow files


SOLUTION: SETTING UP DOCKERHUB AUTHENTICATION FOR GITHUB ACTIONS
----------------------------------------------------------------

Step 1: Create DockerHub Access Token
-------------------------------------

1. Navigate to: https://hub.docker.com/
2. Log in to your DockerHub account
3. Go to: Account Settings ‚Üí Security ‚Üí Access Tokens
4. Click "New Access Token"
5. Configure token:
   - Description: "GitHub Actions MLOps Pipeline" (or descriptive name)
   - Access permissions: Select "Read, Write, Delete" or "Read & Write" (minimum)
6. Click "Generate"
7. **CRITICAL**: Copy the token immediately! You won't see it again
8. Store token securely (password manager, secure note)

‚úì DO: Create tokens with minimal required permissions
‚úì DO: Use descriptive names for tokens
‚úì DO: Set expiration dates for tokens (security best practice)
‚ùå DON'T: Share tokens or commit them to git
‚ùå DON'T: Use your account password (use access tokens instead)


Step 2: Add Secrets to GitHub Repository
----------------------------------------

METHOD 1: Via GitHub Web Interface
----------------------------------

1. Navigate to your repository: https://github.com/YOUR_USERNAME/YOUR_REPO
2. Click "Settings" tab (top navigation)
3. In left sidebar: "Secrets and variables" ‚Üí "Actions"
4. You'll see two tabs: "Secrets" and "Variables"

5. Add Secret (for password/token):
   a. Click "New repository secret"
   b. Name: DOCKERHUB_TOKEN
   c. Value: Paste the DockerHub access token from Step 1
   d. Click "Add secret"

6. Add Variable (for username):
   a. Switch to "Variables" tab
   b. Click "New repository variable"
   c. Name: DOCKERHUB_USERNAME
   d. Value: Your DockerHub username (e.g., "rupeebw")
   e. Click "Add variable"

‚úì Secret names must match exactly what's in your workflow file
‚úì Secret names are case-sensitive: DOCKERHUB_TOKEN ‚â† dockerhub_token


METHOD 2: Via GitHub CLI (Command Line)
---------------------------------------

If you prefer command-line setup:

```bash
# Install GitHub CLI (if not already installed)
# macOS: brew install gh
# Linux: See https://cli.github.com/

# Authenticate GitHub CLI
gh auth login

# Set the secret (you'll be prompted to enter the token)
gh secret set DOCKERHUB_TOKEN

# Alternative: Set from file or environment variable
echo "YOUR_TOKEN_HERE" | gh secret set DOCKERHUB_TOKEN

# Set the variable
gh variable set DOCKERHUB_USERNAME --body "rupeebw"

# Verify secrets are set (shows names only, not values)
gh secret list
gh variable list
```


Step 3: Using Secrets in GitHub Actions Workflow
------------------------------------------------

Example from your ml-pipeline.yml:

```yaml
- name: Log in to DockerHub Container Registry
  uses: docker/login-action@v3
  with:
    registry: docker.io
    username: ${{ vars.DOCKERHUB_USERNAME }}      # From Variables
    password: ${{ secrets.DOCKERHUB_TOKEN }}      # From Secrets
```

‚úì Secrets are accessed via: ${{ secrets.SECRET_NAME }}
‚úì Variables are accessed via: ${{ vars.VARIABLE_NAME }}
‚ùå NEVER hardcode credentials: username: "rupeebw" (BAD!)


Step 4: Verify and Re-run Failed Workflow
-----------------------------------------

After adding secrets:

METHOD 1: Via GitHub Web Interface
1. Go to "Actions" tab in your repository
2. Click on the failed workflow run
3. Click "Re-run failed jobs" or "Re-run all jobs"
4. Monitor the workflow - it should now authenticate successfully

METHOD 2: Via GitHub CLI
```bash
# List recent workflow runs
gh run list

# Re-run the latest failed run
gh run rerun --failed

# Watch the workflow progress
gh run watch
```


ENVIRONMENT-SPECIFIC SECRETS (Advanced)
---------------------------------------

For different environments (dev, staging, production):

1. In GitHub Settings ‚Üí Environments
2. Create environments: "dev", "staging", "production"
3. Add environment-specific secrets and variables
4. Add protection rules (e.g., require approval for production)

In workflow file:
```yaml
jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: production  # Uses production environment secrets
    steps:
      - name: Deploy
        env:
          API_KEY: ${{ secrets.API_KEY }}  # Uses production API_KEY
```


COMMON MISTAKES AND HOW TO AVOID THEM:
--------------------------------------

Mistake 1: Wrong Secret Name
‚ùå Workflow uses: ${{ secrets.DOCKER_TOKEN }}
‚ùå Secret named: DOCKERHUB_TOKEN
‚úì Solution: Names must match EXACTLY

Mistake 2: Using Secret Instead of Variable (or vice versa)
‚ùå Username in secrets: ${{ secrets.DOCKERHUB_USERNAME }}
‚úì Correct: ${{ vars.DOCKERHUB_USERNAME }}

Mistake 3: Expired or Revoked Tokens
‚ùå Token was deleted or expired in DockerHub
‚úì Solution: Create new token and update secret

Mistake 4: Insufficient Permissions
‚ùå Token only has "Read" permission, but workflow needs "Write"
‚úì Solution: Create token with appropriate permissions

Mistake 5: Forgetting to Copy Token
‚ùå Didn't save token when created (can't retrieve later)
‚úì Solution: Delete old token, create new one

Mistake 6: Environment Not Set
‚ùå Secret exists in environment "production" but job doesn't specify environment
‚úì Solution: Add environment: production to job


SECURITY BEST PRACTICES:
------------------------

1. Token Management:
   ‚úì Use tokens with minimal required permissions
   ‚úì Set expiration dates for tokens (e.g., 90 days)
   ‚úì Rotate tokens regularly
   ‚úì Revoke unused tokens
   ‚úì Use separate tokens for different purposes

2. Secret Hygiene:
   ‚úì Never commit secrets to git
   ‚úì Never print secrets in logs
   ‚úì Use .gitignore for sensitive files
   ‚úì Audit secret access regularly
   ‚úì Delete secrets when no longer needed

3. Workflow Security:
   ‚úì Use specific action versions (not @latest)
   ‚úì Review third-party actions before using
   ‚úì Limit workflow permissions (use permissions: block)
   ‚úì Use environment protection rules for production
   ‚úì Enable branch protection rules

4. Monitoring:
   ‚úì Monitor workflow runs for unauthorized access
   ‚úì Set up alerts for workflow failures
   ‚úì Review audit logs periodically


TROUBLESHOOTING AUTHENTICATION ERRORS:
--------------------------------------

Error: "Error: Password required"
Solution:
1. Verify DOCKERHUB_TOKEN secret exists: gh secret list
2. Check secret name matches workflow file exactly
3. Ensure token is valid in DockerHub (not expired/revoked)
4. Recreate token if necessary

Error: "Error: denied: requested access to the resource is denied"
Solution:
1. Check DockerHub username is correct
2. Verify token has Write permissions (not just Read)
3. Ensure repository name in workflow matches DockerHub repo

Error: "Error: Bad credentials"
Solution:
1. Token might be corrupted (extra spaces, newlines)
2. Re-create secret by copying token exactly
3. Ensure using token, not password

Error: Secret not found in environment
Solution:
1. Add environment: to job definition
2. Or move secret from environment-level to repository-level
3. Check environment name matches exactly


CHECKLIST FOR DOCKERHUB AUTHENTICATION SETUP:
---------------------------------------------

‚ñ° DockerHub account exists
‚ñ° DockerHub access token created with Write permissions
‚ñ° Token saved securely
‚ñ° DOCKERHUB_TOKEN secret added to GitHub repository
‚ñ° DOCKERHUB_USERNAME variable added to GitHub repository
‚ñ° Secret names match workflow file exactly (case-sensitive)
‚ñ° Workflow file references secrets correctly (${{ secrets.NAME }})
‚ñ° Workflow tested and authentication successful
‚ñ° Token expiration date noted (for future rotation)


APPLYING THESE LEARNINGS TO OTHER SERVICES:
-------------------------------------------

The same pattern applies to other container registries and services:

AWS ECR (Elastic Container Registry):
```yaml
- name: Configure AWS credentials
  uses: aws-actions/configure-aws-credentials@v4
  with:
    aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
    aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    aws-region: us-east-1

- name: Login to Amazon ECR
  uses: aws-actions/amazon-ecr-login@v2
```

GitHub Container Registry (GHCR):
```yaml
- name: Log in to GitHub Container Registry
  uses: docker/login-action@v3
  with:
    registry: ghcr.io
    username: ${{ github.actor }}
    password: ${{ secrets.GITHUB_TOKEN }}  # Automatically provided
```

Google Container Registry (GCR):
```yaml
- name: Authenticate to Google Cloud
  uses: google-github-actions/auth@v2
  with:
    credentials_json: ${{ secrets.GCP_CREDENTIALS }}
```


KEY TAKEAWAYS FOR CI/CD SECRETS:
--------------------------------

1. SEPARATION: Use secrets for sensitive data, variables for configuration

2. SECURITY: Never commit secrets to git or expose in logs

3. PERMISSIONS: Grant minimal required permissions to tokens

4. NAMING: Secret names must match workflow references exactly

5. ROTATION: Regularly rotate tokens and update secrets

6. ENVIRONMENTS: Use environment-specific secrets for different stages

7. TESTING: Always test authentication after adding secrets

8. DOCUMENTATION: Document what secrets are needed for the pipeline

9. MONITORING: Monitor workflow runs and audit secret access

10. RECOVERY: Know how to recreate and update secrets when needed


REAL-WORLD EXAMPLE: COMPLETE SETUP FLOW
---------------------------------------

Scenario: Setting up DockerHub authentication for ML pipeline

1. Developer creates DockerHub access token (Step 1)
2. Developer adds DOCKERHUB_TOKEN secret to GitHub (Step 2)
3. Developer adds DOCKERHUB_USERNAME variable to GitHub (Step 2)
4. Developer commits workflow file with docker/login-action (Step 3)
5. GitHub Actions runs workflow, authenticates, pushes image (Step 4)
6. Developer monitors workflow, verifies successful push (Step 4)
7. Developer sets reminder to rotate token in 90 days (Security)

Result: Automated Docker image builds and deployments to DockerHub! üöÄ


ADDITIONAL RESOURCES:
--------------------

GitHub Documentation:
- Encrypted Secrets: https://docs.github.com/en/actions/security-guides/encrypted-secrets
- Environment Variables: https://docs.github.com/en/actions/learn-github-actions/variables
- GitHub CLI: https://cli.github.com/manual/gh_secret

DockerHub Documentation:
- Access Tokens: https://docs.docker.com/security/for-developers/access-tokens/
- Docker Login Action: https://github.com/docker/login-action

Security Resources:
- OWASP Secrets Management: https://cheatsheetseries.owasp.org/cheatsheets/Secrets_Management_Cheat_Sheet.html
- GitHub Actions Security: https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions


================================================================================
END OF GUIDE
================================================================================
